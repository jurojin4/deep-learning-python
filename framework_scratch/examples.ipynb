{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b97c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trainer import Trainer\n",
    "from optimizer import SGD\n",
    "from module import Sequential\n",
    "from loss import CrossEntropyLoss, LogLoss, MSELoss\n",
    "from data import Dataset, DataLoader, choose_dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import os\n",
    "import nn\n",
    "import tensyx as ts\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df6d078",
   "metadata": {},
   "source": [
    "# **Binary Classification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbd3853",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "n_samples = 1250\n",
    "n_features = 2\n",
    "dataset_type = \"blobs\"\n",
    "classes = 2\n",
    "learning_rate = 1\n",
    "milestones = []\n",
    "batch_size = 4\n",
    "val_size = 0.2\n",
    "metrics = [\"accuracy\", \"precision\", \"recall\", \"f1_score\"]\n",
    "\n",
    "hi_features = 2**2\n",
    "\n",
    "model = Sequential((nn.Linear(n_features, hi_features), nn.ReLU(), nn.Linear(hi_features, 1), nn.Sigmoid()))\n",
    "print(f\"Model's parameters: {model.count_parameters()}\")\n",
    "optimizer = SGD(model, learning_rate, milestones)\n",
    "loss = LogLoss()\n",
    "\n",
    "X, Y = choose_dataset(dataset_type = dataset_type, random_state=0, last_module=model[-1], n_samples = n_samples, n_features = n_features, classes = classes, biais=0)\n",
    "X_train, X_validation, Y_train, Y_validation = train_test_split(X, Y, test_size=val_size, random_state=42)\n",
    "\n",
    "X_train = ts.Tensor(X_train, requires_grad=False)\n",
    "X_validation = ts.Tensor(X_validation, requires_grad=False)\n",
    "\n",
    "Y_train = ts.Tensor(Y_train, requires_grad=False)\n",
    "Y_validation = ts.Tensor(Y_validation, requires_grad=False)\n",
    "val_size = 0.2\n",
    "train_dataset = Dataset(X_train, Y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=42, shuffle_iteration=True)\n",
    "\n",
    "validation_dataset = Dataset(X_validation, Y_validation)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=42)\n",
    "\n",
    "trainer = Trainer(epochs, model, optimizer, loss, dataset_type, train_loader, num_classes=classes, metrics=metrics)\n",
    "trainer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d752fd",
   "metadata": {},
   "source": [
    "# **Classification Multi-Class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94aee1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "n_samples = 1250\n",
    "n_features = 2\n",
    "dataset_type = \"blobs\"\n",
    "classes = 10\n",
    "learning_rate = 1\n",
    "milestones = []\n",
    "batch_size = 4\n",
    "val_size = 0.2\n",
    "metrics = [\"accuracy\", \"precision\", \"recall\", \"f1_score\"]\n",
    "\n",
    "hi_features = 2**1\n",
    "\n",
    "model = Sequential((nn.Linear(n_features, classes), nn.Softmax()))\n",
    "print(f\"Model's parameters: {model.count_parameters()}\")\n",
    "optimizer = SGD(model, learning_rate, milestones)\n",
    "loss = CrossEntropyLoss()\n",
    "\n",
    "X, Y = choose_dataset(dataset_type = dataset_type, random_state=0, last_module=model[-1], n_samples = n_samples, n_features = n_features, classes = classes, biais=0)\n",
    "X_train, X_validation, Y_train, Y_validation = train_test_split(X, Y, test_size=val_size, random_state=42)\n",
    "\n",
    "X_train = ts.Tensor(X_train, requires_grad=False)\n",
    "X_validation = ts.Tensor(X_validation, requires_grad=False)\n",
    "\n",
    "Y_train = ts.Tensor(Y_train, requires_grad=False)\n",
    "Y_validation = ts.Tensor(Y_validation, requires_grad=False)\n",
    "val_size = 0.2\n",
    "train_dataset = Dataset(X_train, Y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=42, shuffle_iteration=True)\n",
    "\n",
    "validation_dataset = Dataset(X_validation, Y_validation)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=42)\n",
    "\n",
    "trainer = Trainer(epochs, model, optimizer, loss, dataset_type, train_loader, num_classes=classes, metrics=metrics)\n",
    "trainer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b94ff95",
   "metadata": {},
   "source": [
    "# **Non-linear Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bb9d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "n_samples = 10000\n",
    "n_features = 1\n",
    "dataset_type = \"non_linear_regression\"\n",
    "classes = 1\n",
    "learning_rate = 5e-2\n",
    "milestones = []\n",
    "batch_size = 2\n",
    "val_size = 0.1\n",
    "metrics = []\n",
    "\n",
    "hi_features = 2**3\n",
    "\n",
    "model = Sequential(nn.Linear(n_features, hi_features), nn.Sigmoid(), nn.Linear(hi_features, hi_features), nn.Sigmoid(), nn.Linear(hi_features, classes))\n",
    "print(f\"Model's parameters: {model.count_parameters()}\")\n",
    "optimizer = SGD(model, learning_rate, milestones)\n",
    "loss = MSELoss()\n",
    "\n",
    "X, Y = choose_dataset(dataset_type = dataset_type, random_state=0, last_module=model[-1], n_samples = n_samples, n_features = n_features, classes = classes, biais=0)\n",
    "X_train, X_validation, Y_train, Y_validation = train_test_split(X, Y, test_size=val_size, random_state=42)\n",
    "\n",
    "X_train = ts.Tensor(X_train, requires_grad=False)\n",
    "X_validation = ts.Tensor(X_validation, requires_grad=False)\n",
    "\n",
    "Y_train = ts.Tensor(Y_train, requires_grad=False)\n",
    "Y_validation = ts.Tensor(Y_validation, requires_grad=False)\n",
    "\n",
    "train_dataset = Dataset(X_train, Y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=42, shuffle_iteration=True)\n",
    "\n",
    "validation_dataset = Dataset(X_validation, Y_validation)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=42)\n",
    "\n",
    "trainer = Trainer(epochs, model, optimizer, loss, dataset_type, train_loader, num_classes=classes, metrics=metrics)\n",
    "trainer()\n",
    "\n",
    "X = ts.Tensor(ts.np.expand_dims(ts.np.linspace(-30, 30, 1000), -1))\n",
    "\n",
    "_, ax = plt.subplots(1, 1, figsize=(20, 12))\n",
    "ax.spines[\"left\"].set_position(\"zero\")\n",
    "ax.spines[\"bottom\"].set_position(\"zero\")\n",
    "ax.spines[\"top\"].set_visible(False)\n",
    "ax.spines[\"right\"].set_visible(False)\n",
    "\n",
    "ax.plot(X.tensor, ts.np.sin(X.tensor), c=\"blue\", linewidth=1.5, label=\"sin(x)\")\n",
    "ax.plot(X.tensor, model(X).tensor, c=\"red\", linewidth=1.5, label=\"MLP predictions\")\n",
    "ax.plot([2 * ts.np.pi] * 100, ts.np.linspace(-1, 1, 100), c=\"black\", linewidth=2, linestyle=\"dashed\", label=\"2pi\")\n",
    "ax.plot([- 2 * ts.np.pi] * 100, ts.np.linspace(-1, 1, 100), c=\"black\", linewidth=2, linestyle=\"dashdot\", label=\"-2pi\")\n",
    "ax.set_ylim(-2, 2)\n",
    "ax.legend()\n",
    "plt.savefig(os.path.join(os.path.dirname(\"\"), \"documentations/plots\", f\"MLP_sin_predictions_{n_samples}\"), pad_inches=0.)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
