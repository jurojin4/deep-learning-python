experiment name:batch 80|dataset type:classification|dataset:cifar-10|classes:10|image size:(32, 32)|model parameters:64421706|epochs:50|batch:80|optimizer:Adam|learning rate: 1e-05|loss:CrossEntropyLoss
model_checkpoint_1: 2.0866 of loss for validation stage.
model_checkpoint_2: 2.0272 of loss for validation stage.
model_checkpoint_3: 2.0034 of loss for validation stage.
model_checkpoint_4: 1.9908 of loss for validation stage.
model_checkpoint_5: 1.9807 of loss for validation stage.
model_checkpoint_6: 1.9785 of loss for validation stage.
model_checkpoint_7: 1.9544 of loss for validation stage.
model_checkpoint_10: 1.9499 of loss for validation stage.
model_checkpoint_11: 1.9400 of loss for validation stage.
model_checkpoint_13: 1.9384 of loss for validation stage.
model_checkpoint_14: 1.9352 of loss for validation stage.
model_checkpoint_15: 1.9327 of loss for validation stage.
model_checkpoint_16: 1.9283 of loss for validation stage.
model_checkpoint_18: 1.9253 of loss for validation stage.
model_checkpoint_19: 1.9223 of loss for validation stage.
model_checkpoint_20: 1.9183 of loss for validation stage.
model_checkpoint_21: 1.9156 of loss for validation stage.
model_checkpoint_22: 1.9149 of loss for validation stage.
model_checkpoint_23: 1.9123 of loss for validation stage.
model_checkpoint_25: 1.9105 of loss for validation stage.
model_checkpoint_30: 1.9091 of loss for validation stage.
model_checkpoint_31: 1.9089 of loss for validation stage.
model_checkpoint_33: 1.9046 of loss for validation stage.
model_checkpoint_38: 1.9014 of loss for validation stage.
model_checkpoint_40: 1.9012 of loss for validation stage.
model_checkpoint_41: 1.8969 of loss for validation stage.
model_checkpoint_43: 1.8934 of loss for validation stage.
model_checkpoint_46: 1.8857 of loss for validation stage.